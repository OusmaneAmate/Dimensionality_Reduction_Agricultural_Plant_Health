{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d304c892-ce9d-4479-a798-deba98c019ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA,KernelPCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "import tensorflow as tf\n",
    "from sklearn.manifold import Isomap,MDS\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943471e7-a34c-4ced-b6c7-5e8df7c7f940",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c36f219-2f81-44b6-a069-8c50cd4ff05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATASETS_FILE_NAMES = {\n",
    "    \"Carotte\": {\n",
    "        \"x\": \"combined_daily_meteo.csv\",\n",
    "        \"y\": \"carrot_no_sensitive_data.csv\",\n",
    "        \"d\": \"field_distance.txt\"\n",
    "    },\n",
    "    \"Laitue\": {\n",
    "        \"x\": \"combined_daily_meteo.csv\",\n",
    "        \"y\": \"lettuce_no_sensitive_data.csv\",\n",
    "        \"d\": \"field_distance.txt\"\n",
    "    },\n",
    "    \"Oignon\": {\n",
    "        \"x\": \"combined_daily_meteo.csv\",\n",
    "        \"y\": \"onion_no_sensitive_data.csv\",\n",
    "        \"d\": \"field_distance.txt\"\n",
    "    }\n",
    "}\n",
    "\n",
    "DATASETS = {}\n",
    "for name in DATASETS_FILE_NAMES:\n",
    "    DATASETS[name] = {}\n",
    "    for k, v in DATASETS_FILE_NAMES[name].items():\n",
    "        if k == \"d\":\n",
    "            DATASETS[name][k] = pd.read_csv(f\"data/{name}/{v}\", header=None)\n",
    "        else:\n",
    "            DATASETS[name][k] = pd.read_csv(f\"data/{name}/{v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcecdbb-ebd7-44e1-a85b-866e05613545",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e39378-1dce-4d63-acfc-cbc462c41d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, make_scorer, precision_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "DATASETS = {}\n",
    "for name in DATASETS_FILE_NAMES:\n",
    "    DATASETS[name] = {}\n",
    "    for k, v in DATASETS_FILE_NAMES[name].items():\n",
    "        if k == \"d\":\n",
    "            DATASETS[name][k] = pd.read_csv(f\"data/{name}/{v}\", header=None)\n",
    "        else:\n",
    "            DATASETS[name][k] = pd.read_csv(f\"data/{name}/{v}\")\n",
    "\n",
    "\n",
    "def normalize(sub_df):\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    sub_df_scaled = min_max_scaler.fit_transform(sub_df)\n",
    "    return(pd.DataFrame(sub_df_scaled, index=sub_df.index, columns=sub_df.columns))\n",
    "\n",
    "\n",
    "def preprocess_data_classification(crop, obs_df, meteo_df):\n",
    "    obs_df.rename(columns={'SampleDate':'Date'}, inplace=True)\n",
    "    if crop == 'Oignon':\n",
    "        \n",
    "        obs_df.loc[obs_df['cote_b_squamosa'] >= 1, 'cote_b_squamosa'] = 1\n",
    "        obs_df.loc[obs_df['cote_p_destructor'] >= 1, 'cote_p_destructor'] = 1\n",
    "        obs_df.loc[obs_df['cote_s_vesicarium'] >= 1, 'cote_s_vesicarium'] = 1 \n",
    "        unique_sample_date = obs_df['Date'].unique()\n",
    "        unique_sample_date = meteo_df[meteo_df['Date'].isin(unique_sample_date)]\n",
    "        combined_df = obs_df.merge(meteo_df, on=['FarmID', 'Date'])\n",
    "        label_df = combined_df.get('cote_b_squamosa')\n",
    "        combined_df = combined_df.drop(['cote_b_squamosa', 'cote_p_destructor', 'cote_s_vesicarium', 'Bulb_onions_date'], axis=1)\n",
    "    elif crop == 'Laitue':\n",
    "        obs_df.loc[obs_df['cote_b_lactucae'] >= 1, 'cote_b_lactucae'] = 1\n",
    "        obs_df.loc[obs_df['incidence_sclerotinia'] >= 1, 'incidence_sclerotinia'] = 1 \n",
    "        obs_df.loc[obs_df['incidence_b_cinerea'] >= 1, 'incidence_b_cinerea'] = 1 \n",
    "        unique_sample_date = obs_df['Date'].unique()\n",
    "        unique_sample_date = meteo_df[meteo_df['Date'].isin(unique_sample_date)]\n",
    "        combined_df = obs_df.merge(meteo_df, on=['FarmID', 'Date'])\n",
    "        label_df = combined_df.get('cote_b_lactucae')\n",
    "        combined_df = combined_df.drop(['cote_b_lactucae', 'incidence_sclerotinia', 'incidence_b_cinerea', 'Pommaison_lettuce_date'], axis=1)\n",
    "    elif crop == 'Carotte':\n",
    "        print(obs_df[['cote_c_carotae','incidence_a_dauci','incidence_s_sclerotiorum']])\n",
    "        obs_df = obs_df.drop(obs_df[obs_df['FarmID'] == 0].index)\n",
    "        obs_df.loc[obs_df['cote_c_carotae'] >= 1, 'cote_c_carotae'] = 1\n",
    "        obs_df.loc[obs_df['incidence_s_sclerotiorum'] >= 1, 'incidence_s_sclerotiorum'] = 1 \n",
    "        obs_df.loc[obs_df['incidence_a_dauci'] >= 1, 'incidence_a_dauci'] = 1\n",
    "        unique_sample_date = obs_df['Date'].unique()\n",
    "        unique_sample_date = meteo_df[meteo_df['Date'].isin(unique_sample_date)]\n",
    "        combined_df = obs_df.merge(meteo_df, on=['FarmID', 'Date'])\n",
    "        label_df = combined_df.get('cote_c_carotae')\n",
    "        combined_df = combined_df.drop(['cote_c_carotae', 'incidence_s_sclerotiorum', 'incidence_a_dauci'], axis=1)\n",
    "    return combined_df, label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aae17a-fa7e-4dab-92a6-309c27e1a41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "def DecisionTreeModel(x, y):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=True)\n",
    "    clf = DecisionTreeRegressor()\n",
    "    param_dist = {\n",
    "        'criterion': ['poisson'],\n",
    "        'max_depth': [1, 2, 3, 4, 5],\n",
    "        'min_samples_split': [5, 10, 20],\n",
    "        'splitter': ['best']\n",
    "    }\n",
    "    scoring = {\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'roc_auc': make_scorer(roc_auc_score),\n",
    "        'f1': make_scorer(f1_score)\n",
    "    }\n",
    "    grid = GridSearchCV(clf, param_grid=param_dist, n_jobs=-1, cv=5, scoring=scoring, refit='accuracy')\n",
    "    grid.fit(x_train, y_train)\n",
    "    clf = grid.best_estimator_\n",
    "    y_pred = clf.predict(x_test)\n",
    "    return r2_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "def kNNModel(x, y):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=True)\n",
    "    clf = KNeighborsRegressor()\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    return r2_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "def RandomForestModel(x, y):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=True)\n",
    "    clf = RandomForestRegressor()\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    return r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ccfba4-0065-4004-a154-6f19c4be16f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_RUNS = 5  \n",
    "models = (\n",
    "    (\"DT\", DecisionTreeModel),\n",
    "    (\"k-NN\", kNNModel),\n",
    "    (\"RF\", RandomForestModel),\n",
    ")\n",
    "\n",
    "for crop in DATASETS:\n",
    "    print(f\"\\nüåæ Culture : {crop}\")\n",
    "    x, y = preprocess_data_classification(crop, DATASETS[crop][\"y\"], DATASETS[crop][\"x\"])\n",
    "\n",
    "   \n",
    "    scaler = StandardScaler()\n",
    "    x_scaled = scaler.fit_transform(x)\n",
    "\n",
    "    \n",
    "    kpca = KernelPCA(n_components=22)\n",
    "    x_kpca = kpca.fit_transform(x_scaled)\n",
    "\n",
    "    print(f\"üìâ KernelPCA : {x.shape[1]} ‚ûù {x_pca.shape[1]} dimensions pour {crop}\")\n",
    "    \n",
    "    \n",
    "    y = y.values if hasattr(y, 'values') else y\n",
    "    y = y / max(y)\n",
    "\n",
    "    \n",
    "    acc_scores = {name: [] for name, _ in models}\n",
    "    prec_scores = {name: [] for name, _ in models}\n",
    "    f_scores = {name: [] for name, _ in models}\n",
    "\n",
    "    for run in range(N_RUNS):\n",
    "        print(f\"   ‚ñ∂Ô∏è Run {run + 1}/{N_RUNS}\")\n",
    "        for name, model in models:\n",
    "             a, p, f = model(x_kpca, y)\n",
    "             acc_scores[name].append(a)\n",
    "             prec_scores[name].append(p)\n",
    "             f_scores[name].append(f)\n",
    "           \n",
    "             \n",
    "             print(f\"    {name}: accuracy= {a:.4}, precision={p:.4}, f1={f:.4}\")\n",
    "   \n",
    "    print(f\"\\nüìä Moyennes des {N_RUNS} runs pour {crop} :\")\n",
    "    for name in acc_scores:\n",
    "        acc_mean = np.mean(acc_scores[name])\n",
    "        prec_mean = np.mean(prec_scores[name])\n",
    "        f1_mean = np.mean(f_scores[name])\n",
    "        print(f\"    ‚ñ∂Ô∏è {name} : Accuracy = {acc_mean:.4f}, Precision = {prec_mean:.4f}, F1-score = {f1_mean:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
